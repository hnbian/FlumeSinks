
#定义source名称
a1.sources = kafka
#定义channel名称
a1.channels = memoryChannel
#定义sink名称
a1.sinks = esSink


# For each one of the sources, the type is defined
#配置source
#指定source类型
a1.sources.kafka.type = org.apache.flume.source.kafka.KafkaSource
#指定zookeeper
a1.sources.kafka.zookeeperConnect = node1.com:2181,node2.com:2181,node3.com:2181
#指定kafka topic
a1.sources.kafka.topic = test
#指定 group
a1.sources.kafka.groupId = flume
#设置超时时间
a1.sources.kafka.kafka.consumer.timeout.ms = 100
a1.sources.kafka.batchSize = 20

#配置channel
a1.channels.memoryChannel.type = memory
#通道容量
a1.channels.memoryChannel.capacity = 1000
#a1.channels.memoryChannel.keep-alive = 100
#a1.channels.memoryChannel.capacity = 1000
#通道事物容量
a1.channels.memoryChannel.transactionCapacity = 100


#配置sink
a1.sinks.esSink.type = org.apache.flume.sink.elasticsearch.ElasticSearchSink
#配置es服务地址
a1.sinks.esSink.hostNames = node3.com:9300,node3.com:9300
#配置es集群名称
a1.sinks.esSink.clusterName = es_CLUSTER
a1.sinks.esSink.serializer = org.apache.flume.sink.elasticsearch.ElasticSearchLogStashEventJsonSerializer

#配置索引名称
a1.sinks.esSink.indexName = kafka_es
a1.sinks.esSink.indexType = bar_type
#a1.sinks.esSink.indexType = logs
#a1.sinks.esSink.indexType = json
a1.sinks.esSink.batchSize = 10
#配置esclient 类型
#a1.sinks.esSink.client = jsonTransport

#指定source 数据发送到哪个channel
a1.sources.kafka.channels = memoryChannel
#指定sink 取哪个channel的数据
a1.sinks.esSink.channel = memoryChannel
